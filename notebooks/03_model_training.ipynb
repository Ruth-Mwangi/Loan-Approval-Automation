{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from utils import print_model_score\n",
    "from visualization import create_bar_chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../data/processed/data_features_selected.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop('AR', axis = 1)\n",
    "y = data['AR']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify = y, random_state=2022)\n",
    "\n",
    "sampling_strategy = 0.6  # Increase minority class to 60% of the majority class\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=2022)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_distributions = {\n",
    "    \n",
    "        'classifier__C': [0.1, 1, 10, 100,200],\n",
    "        'classifier__penalty': ['l2'],\n",
    "        'classifier__solver':  ['lbfgs','newton-cg','liblinear','sag','saga']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "log_model = LogisticRegression(class_weight='balanced', max_iter=4000)\n",
    "\n",
    "log_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', log_model)\n",
    "])\n",
    "\n",
    "log_random_search = RandomizedSearchCV(log_pipeline, param_distributions, cv=10, scoring='f1', n_iter=25, random_state=2022)\n",
    "log_random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = log_random_search.best_params_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "best_log_model_params = {\n",
    "    key.replace('classifier__', ''): value\n",
    "    for key, value in best_params.items()\n",
    "}\n",
    "log_model = LogisticRegression(**best_log_model_params,max_iter=4000)\n",
    "\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test)\n",
    "y_train_pred = log_model.predict(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(log_model, X_train, feature_names=X_train.columns)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value, \n",
    "    shap_values[0].values,\n",
    "    X_test.iloc[0], \n",
    "    feature_names=X_test.columns\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_score(y_train, y_train_pred, train=True)\n",
    "print_model_score(y_test, y_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/logistic_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(log_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify = y, random_state=2022)\n",
    "\n",
    "sampling_strategy = 0.6  # Increase minority class to 60% of the majority class\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=2022)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, \n",
    "                            n_iter=10, scoring='roc_auc', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = xgb_random_search.best_params_\n",
    "best_params['tree_method'] = 'hist'\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(**best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shap Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "\n",
    "shap.force_plot(explainer.expected_value, shap_values[0].values, X_test.iloc[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_score(y_train, y_train_pred, train=True)\n",
    "print_model_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/xgboost_model.pkl', 'wb') as file:\n",
    "    pickle.dump(xgb_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y, random_state=2022)\n",
    "sampling_strategy = 0.6  # Increase minority class to 60% of the majority class\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=2022)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 20, 50, 100],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    rf_model, param_distributions=param_grid, cv=StratifiedKFold(10), n_iter=60, \n",
    "    scoring='f1', n_jobs=-1, verbose=1, random_state=2022\n",
    ")\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = rf_random_search.best_params_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "rf_model = RandomForestClassifier(**best_params)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_score(y_train, y_train_pred, train=True)\n",
    "print_model_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the best hyperparameters for pre-trained models\n",
    "best_log_reg = log_model\n",
    "best_xgb = xgb_model\n",
    "best_rf = rf_model\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('log_reg', best_log_reg),\n",
    "        ('xgb', best_xgb),\n",
    "        ('rf', best_rf)\n",
    "    ],\n",
    "    voting='soft' \n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ensemble_model.predict(X_train)\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model performance\n",
    "print_model_score(y_train, y_train_pred, train=True)\n",
    "print_model_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/ensemble_model.pkl', 'wb') as file:\n",
    "    pickle.dump(ensemble_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba_logistic = log_model.predict_proba(X)[:, 1]\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X)[:, 1]\n",
    "y_pred_proba_rf = rf_model.predict_proba(X)[:, 1]\n",
    "y_pred_proba_ensemble = ensemble_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Calculate ROC curves\n",
    "fpr_logistic, tpr_logistic, _ = roc_curve(y, y_pred_proba_logistic)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y, y_pred_proba_xgb)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y, y_pred_proba_rf)\n",
    "fpr_ensemble, tpr_ensemble, _ = roc_curve(y, y_pred_proba_ensemble)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc_logistic = auc(fpr_logistic, tpr_logistic)\n",
    "roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "roc_auc_ensemble = auc(fpr_ensemble, tpr_ensemble)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='red', lw=2, label=f'Logistic Regression (AUC = {roc_auc_logistic:.2f})')\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='yellow', lw=2, label=f'XGBoost (AUC = {roc_auc_xgb:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, color='blue', lw=2, label=f'Random Forest (AUC = {roc_auc_xgb:.2f})')\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, color='orange', lw=2, label=f'Ensemble (AUC = {roc_auc_xgb:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"../reports/figures/roc.png\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-score,accuracy,recall,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict and calculate metrics for each model\n",
    "# RandomForest\n",
    "rf_y_test_pred = rf_model.predict(X)\n",
    "rf_metrics = {\n",
    "    \"Model\": \"RandomForest\",\n",
    "    \"Accuracy\": accuracy_score(y, rf_y_test_pred)* 100,\n",
    "    \"Precision\": precision_score(y, rf_y_test_pred)* 100,\n",
    "    \"Recall\": recall_score(y, rf_y_test_pred)* 100,\n",
    "    \"F1-score\": f1_score(y, rf_y_test_pred)* 100\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "xgb_y_test_pred = xgb_model.predict(X_test)\n",
    "xgb_metrics = {\n",
    "    \"Model\": \"XGBoost\",\n",
    "    \"Accuracy\": accuracy_score(y_test, xgb_y_test_pred)* 100,\n",
    "    \"Precision\": precision_score(y_test, xgb_y_test_pred)* 100,\n",
    "    \"Recall\": recall_score(y_test, xgb_y_test_pred)* 100,\n",
    "    \"F1-score\": f1_score(y_test, xgb_y_test_pred)* 100\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "log_y_test_pred = log_model.predict(X_test)\n",
    "log_metrics = {\n",
    "    \"Model\": \"Logistic Regression\",\n",
    "    \"Accuracy\": accuracy_score(y_test, log_y_test_pred)* 100,\n",
    "    \"Precision\": precision_score(y_test, log_y_test_pred)* 100,\n",
    "    \"Recall\": recall_score(y_test, log_y_test_pred)* 100,\n",
    "    \"F1-score\": f1_score(y_test, log_y_test_pred)* 100\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "ensemble_y_test_pred = ensemble_model.predict(X_test)\n",
    "ensemble_metrics = {\n",
    "    \"Model\": \"Ensemble\",\n",
    "    \"Accuracy\": accuracy_score(y_test, ensemble_y_test_pred)* 100,\n",
    "    \"Precision\": precision_score(y_test, ensemble_y_test_pred)* 100,\n",
    "    \"Recall\": recall_score(y_test, ensemble_y_test_pred)* 100,\n",
    "    \"F1-score\": f1_score(y_test, ensemble_y_test_pred)* 100\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([rf_metrics, xgb_metrics, log_metrics,ensemble_metrics])\n",
    "\n",
    "metrics_melted = metrics_df.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "\n",
    "# Create a grouped bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"Model\", y=\"Value\", hue=\"Metric\", data=metrics_melted)\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.ylabel(\"Score %\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-Recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('RandomForest', rf_model),\n",
    "    ('XGBoost', xgb_model),\n",
    "    ('Logistic Regression', log_model),\n",
    "    ('Ensemble', ensemble_model)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (name, model) in zip(axes, models):\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "    \n",
    "    ax.plot(thresholds, precision[:-1], label=f\"Precision\")\n",
    "    ax.plot(thresholds, recall[:-1], label=f\"Recall\")\n",
    "    \n",
    "    ax.set_xlabel(\"Threshold\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(f\"{name} Precision and Recall for Different Thresholds\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
